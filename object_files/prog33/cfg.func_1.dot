digraph "CFG for 'func_1' function" {
	label="CFG for 'func_1' function";

	Node0xaa68530 [shape=record,label="{entry:\l  %l_8 = alloca i32, align 4\l  %l_1275 = alloca i16*, align 8\l  %l_1278 = alloca i8*, align 8\l  %l_1281 = alloca i64*, align 8\l  %l_1735 = alloca [5 x [8 x i64*]], align 16\l  %l_1736 = alloca [3 x [8 x [4 x i32]]], align 16\l  %l_1737 = alloca %struct.S3, align 4\l  %l_2153 = alloca [5 x [9 x i32*]], align 16\l  %l_2155 = alloca i32, align 4\l  %l_2156 = alloca i32, align 4\l  %l_2157 = alloca i64, align 8\l  %l_2158 = alloca i8, align 1\l  %l_2159 = alloca i8, align 1\l  %l_2160 = alloca i16, align 2\l  %i = alloca i32, align 4\l  %j = alloca i32, align 4\l  %k = alloca i32, align 4\l  store i32 1204955349, i32* %l_8, align 4\l  store i16* getelementptr inbounds (%struct.S4* bitcast (\{ i8, i8, [2 x i8],\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i16, [2 x i8], i8, i8, i8, i8 \}*\l... @g_772 to %struct.S4*), i32 0, i32 5), i16** %l_1275, align 8\l  store i8* @g_40, i8** %l_1278, align 8\l  store i64* @g_188, i64** %l_1281, align 8\l  %0 = bitcast [5 x [8 x i64*]]* %l_1735 to i8*\l  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %0, i8* bitcast ([5 x [8 x i64*]]*\l... @func_1.l_1735 to i8*), i64 320, i32 16, i1 false)\l  %1 = bitcast [3 x [8 x [4 x i32]]]* %l_1736 to i8*\l  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %1, i8* bitcast ([3 x [8 x [4 x\l... i32]]]* @func_1.l_1736 to i8*), i64 384, i32 16, i1 false)\l  %2 = bitcast %struct.S3* %l_1737 to i8*\l  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %2, i8* bitcast (%struct.S3*\l... @func_1.l_1737 to i8*), i64 4, i32 4, i1 false)\l  %3 = bitcast [5 x [9 x i32*]]* %l_2153 to i8*\l  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %3, i8* bitcast ([5 x [9 x i32*]]*\l... @func_1.l_2153 to i8*), i64 360, i32 16, i1 false)\l  store i32 -1, i32* %l_2155, align 4\l  store i32 8, i32* %l_2156, align 4\l  store i64 8, i64* %l_2157, align 8\l  store i8 99, i8* %l_2158, align 1\l  store i8 -1, i8* %l_2159, align 1\l  store i16 7200, i16* %l_2160, align 2\l  %4 = load i32* %l_8, align 4\l  %conv = trunc i32 %4 to i16\l  %5 = load i32* %l_8, align 4\l  %conv1 = trunc i32 %5 to i16\l  %6 = load volatile i64* @g_24, align 8\l  %conv2 = trunc i64 %6 to i16\l  %7 = load i32* %l_8, align 4\l  %call = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %conv2,\l... i32 %7)\l  %call3 = call zeroext i8 @func_25(i8 zeroext 0)\l  %conv4 = zext i8 %call3 to i64\l  %xor = xor i64 -5, %conv4\l  %conv5 = trunc i64 %xor to i16\l  %call6 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %call, i16\l... zeroext %conv5)\l  %8 = load i16** %l_1275, align 8\l  store i16 %call6, i16* %8, align 2\l  %call7 = call zeroext i16 @safe_mod_func_uint16_t_u_u(i16 zeroext %conv1,\l... i16 zeroext %call6)\l  %conv8 = trunc i16 %call7 to i8\l  %9 = load i8** %l_1278, align 8\l  store i8 0, i8* %9, align 1\l  %call9 = call zeroext i8 @safe_lshift_func_uint8_t_u_s(i8 zeroext 0, i32 7)\l  %conv10 = zext i8 %call9 to i32\l  %10 = load i32* %l_8, align 4\l  %cmp = icmp sle i32 %conv10, %10\l  %conv11 = zext i1 %cmp to i32\l  %conv12 = trunc i32 %conv11 to i8\l  %call13 = call signext i8 @safe_add_func_int8_t_s_s(i8 signext 0, i8 signext\l... %conv12)\l  %conv14 = sext i8 %call13 to i64\l  %cmp15 = icmp ugt i64 %conv14, 0\l  %conv16 = zext i1 %cmp15 to i32\l  %bf.load = load i32* bitcast ([4 x i8]* getelementptr inbounds ([6 x [6 x [1\l... x %struct.S1]]]* bitcast (\<\{ \<\{ \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8,\l... [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64,\l... i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>\l... \}\>, \<\{ \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8,\l... i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3\l... x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64,\l... i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\> \}\>, \<\{ \<\{ \{ i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x\l... i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8,\l... i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8,\l... [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64,\l... i8, i8, i8, i8, i8, [3 x i8] \} \}\> \}\>, \<\{ \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \}\l... \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8,\l... i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3\l... x i8] \} \}\> \}\>, \<\{ \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64,\l... i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \}\l... \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8,\l... i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\> \}\>, \<\{ \<\{\l... \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8,\l... i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64,\l... i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8,\l... i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \}\l... \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i64, i64, i8, i8,\l... i8, i8, i8, [3 x i8] \} \}\>, \<\{ \{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i64, i64, i8, i8, i8, i8, i8, [3 x i8] \} \}\> \}\> \}\>* @g_540 to [6 x [6 x [1\l... x %struct.S1]]]*), i32 0, i64 5, i64 5, i64 0, i32 1) to i32*), align 4\l  %bf.shl = shl i32 %bf.load, 7\l  %bf.ashr = ashr i32 %bf.shl, 16\l  %cmp17 = icmp sge i32 %conv16, %bf.ashr\l  %conv18 = zext i1 %cmp17 to i32\l  %conv19 = sext i32 %conv18 to i64\l  %11 = load i64** %l_1281, align 8\l  store i64 %conv19, i64* %11, align 8\l  %12 = load i32* %l_8, align 4\l  %conv20 = trunc i32 %12 to i16\l  %bf.load21 = load i24* bitcast ([3 x i8]* getelementptr inbounds\l... (%struct.S0* bitcast (\{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8 \}* @g_308 to %struct.S0*), i32 0, i32 5) to i24*), align 1\l  %bf.lshr = lshr i24 %bf.load21, 2\l  %bf.clear = and i24 %bf.lshr, 131071\l  %bf.cast = zext i24 %bf.clear to i32\l  %13 = load i32* %l_8, align 4\l  %conv22 = trunc i32 %13 to i16\l  %call23 = call signext i8 @func_12(i8 signext %conv8, i64 %conv19, i16\l... zeroext %conv20, i32 %bf.cast, i16 signext %conv22)\l  %conv24 = sext i8 %call23 to i64\l  %or = or i64 %conv24, 3\l  %conv25 = trunc i64 %or to i8\l  %14 = load i32* %l_8, align 4\l  %conv26 = trunc i32 %14 to i16\l  %call27 = call signext i16 @func_9(i8 zeroext %conv25, i16 signext %conv26)\l  %conv28 = sext i16 %call27 to i64\l  %cmp29 = icmp ugt i64 %conv28, 0\l  %conv30 = zext i1 %cmp29 to i32\l  %arrayidx = getelementptr inbounds [3 x [8 x [4 x i32]]]* %l_1736, i32 0,\l... i64 0\l  %arrayidx31 = getelementptr inbounds [8 x [4 x i32]]* %arrayidx, i32 0, i64 1\l  %arrayidx32 = getelementptr inbounds [4 x i32]* %arrayidx31, i32 0, i64 1\l  %15 = load i32* %arrayidx32, align 4\l  %or33 = or i32 %15, %conv30\l  store i32 %or33, i32* %arrayidx32, align 4\l  %conv34 = sext i32 %or33 to i64\l  %f0 = getelementptr inbounds %struct.S3* %l_1737, i32 0, i32 0\l  %16 = load i32* %f0, align 4\l  %conv35 = zext i32 %16 to i64\l  %f036 = getelementptr inbounds %struct.S3* %l_1737, i32 0, i32 0\l  %17 = load i32* %f036, align 4\l  %coerce.dive = getelementptr %struct.S3* %l_1737, i32 0, i32 0\l  %18 = load i32* %coerce.dive\l  %call37 = call i32 @func_2(i16 zeroext %conv, i64 %conv34, i32 %18, i64\l... %conv35, i32 %17)\l  %bf.load38 = load i32* bitcast ([4 x i8]* getelementptr inbounds\l... (%struct.S0* bitcast (\{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8 \}* @g_308 to %struct.S0*), i32 0, i32 6) to i32*), align 4\l  %bf.shl39 = shl i32 %bf.load38, 12\l  %bf.ashr40 = ashr i32 %bf.shl39, 12\l  %and = and i32 %bf.ashr40, %call37\l  %bf.load41 = load i32* bitcast ([4 x i8]* getelementptr inbounds\l... (%struct.S0* bitcast (\{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8 \}* @g_308 to %struct.S0*), i32 0, i32 6) to i32*), align 4\l  %bf.value = and i32 %and, 1048575\l  %bf.clear42 = and i32 %bf.load41, -1048576\l  %bf.set = or i32 %bf.clear42, %bf.value\l  store i32 %bf.set, i32* bitcast ([4 x i8]* getelementptr inbounds\l... (%struct.S0* bitcast (\{ i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8,\l... i8, i8, i8 \}* @g_308 to %struct.S0*), i32 0, i32 6) to i32*), align 4\l  %bf.result.shl = shl i32 %bf.value, 12\l  %bf.result.ashr = ashr i32 %bf.result.shl, 12\l  %19 = load i16* %l_2160, align 2\l  %inc = add i16 %19, 1\l  store i16 %inc, i16* %l_2160, align 2\l  %20 = bitcast %struct.S4* %agg.result to i8*\l  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %20, i8* getelementptr inbounds (\{\l... i8, i8, [2 x i8], i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i16, [2 x i8],\l... i8, i8, i8, i8 \}* @g_2163, i32 0, i32 0), i64 24, i32 4, i1 false)\l  ret void\l}"];
}
